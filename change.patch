diff --git a/docs/COLLABORATIVE_EDITING_MODEL.md b/docs/COLLABORATIVE_EDITING_MODEL.md
new file mode 100644
index 0000000..64652e7
--- /dev/null
+++ b/docs/COLLABORATIVE_EDITING_MODEL.md
@@ -0,0 +1,53 @@
+# Collaborative Editing Model: Operation DAG
+
+## Overview
+This document outlines the foundational principles for the collaborative editing model in Tmux-FSM, based on **Operation DAGs** (Directed Acyclic Graphs). This approach departs from traditional linear undo/redo stacks and OT/CRDT approaches by treating the edit history as a causal graph of immutable semantic operations.
+
+## Core Concepts
+
+### 1. Operation DAG vs. Linear History
+*   **Linear History (Legacy)**: A stack of states or operations (Undo/Redo). Branching (undoing then doing new work) destroys 'future' history.
+*   **Operation DAG (Weaver)**: Every operation is a node. 
+    *   **Node**: Contains a `ResolvedOperation` (Atomic, Semantic).
+    *   **Edges**: Represent causal dependencies (`Parent` pointers).
+    *   **Immutability**: Once created, a node is never modified.
+    *   **Branching**: "Undoing" is simply moving the current view pointer to an ancestor. "Redoing" is moving it to a descendant. Creating a new edit from an old state creates a **New Branch**.
+
+### 2. Semantic Diffing
+Since edits are semantic (e.g., "Delete Function Foo", "Rename Variable X"), diffing is structured:
+*   **Diff(A, B)**: The set of DAG nodes present in B's ancestry but not in A's.
+*   **Path**: Topological ordering of these nodes represents the "Patch".
+
+### 3. Collaboration & Merging
+When two users edit concurrently:
+*   User A creates Node `nA` with parent `P`.
+*   User B creates Node `nB` with parent `P`.
+*   **State divergence**: `Tips = {nA, nB}`.
+
+#### Automatic Merging
+To converge, we create a **Merge Node** `nM`:
+*   `nM.Parents = {nA, nB}`.
+*   `nM.Operation` = Result of reconciling `nA` and `nB`.
+
+#### Conflict Detection
+Unlike text-based merge (which fails on overlapping lines), we use **Semantic Collision**:
+1.  **Spatial Conflict**: Do operations touch the same `LineID` ranges?
+2.  **Semantic Conflict**: Does `nB` modify a variable that `nA` deleted?
+3.  **Resolution Strategy**:
+    *   **Conservative**: If collision detected, prompt user (Manual Merge).
+    *   **Optimistic**: If spatially disjoint, apply both.
+
+### 4. Git Integration
+The Operation DAG maps naturally to Git's object model but at a finer granularity:
+*   **Commit** ≈ Checkpoint of DAG state.
+*   **Review**: Instead of reviewing "Changed lines 10-12", review "Refactor Function X (composed of nodes N1..N5)".
+
+### 5. Implementation Status (Phase 7)
+*   [x] **DAG Structure**: `editor/dag.go` defined `DAGNode` and `OperationDAG`.
+*   [x] **Traversal Logic**: `editor/dag_traversal.go` implements `GetAncestors`, `FindLCA`, `Diff`.
+*   [x] **Shadow Engine Integration**: `ShadowEngine` maintains a live DAG of local edits.
+*   [ ] **Merge Logic**: To be implemented in Phase 8 (`editor/dag_merge.go`).
+
+## Future Work
+*   **Rebase**: Reparenting a chain of nodes onto a new base.
+*   **Squash**: Collapsing a subgraph into a single composite semantic operation.
diff --git a/docs/EDITOR_IR_SPEC.md b/docs/EDITOR_IR_SPEC.md
new file mode 100644
index 0000000..2f59baf
--- /dev/null
+++ b/docs/EDITOR_IR_SPEC.md
@@ -0,0 +1,77 @@
+# Editor IR Design Specification
+
+## 1. Overview
+The Editor Intermediate Representation (IR) is the backbone of the Tmux-FSM's next-generation editing engine. It represents the editing history not as a linear sequence of states, but as a Directed Acyclic Graph (DAG) of atomic, semantic operations. This structure enables advanced features like non-linear undo/redo, collaborative editing, and semantic diffing.
+
+## 2. Data Structure
+
+### 2.1. DAG Node
+Each node in the DAG represents an atomic edit operation.
+
+```go
+type DAGNode struct {
+	ID        DAGNodeID          `json:"id"`        // Unique UUID
+	Operation ResolvedOperation  `json:"operation"` // The atomic edit
+	Parents   []DAGNodeID        `json:"parents"`   // Causal dependencies
+	Timestamp int64              `json:"timestamp"` // Unix/Lamport timestamp
+	Meta      map[string]string  `json:"meta"`      // Extensible metadata
+}
+```
+
+### 2.2. Resolved Operation
+The payload of a node is a `ResolvedOperation`, which is a strictly typed, location-aware description of the edit.
+
+```go
+type ResolvedOperation struct {
+    Kind     ResolvedOperationKind // OpInsert, OpDelete, OpMove
+    BufferID BufferID
+    Anchor   Cursor                // Starting position
+    // For Insert:
+    Text     string
+    // For Delete:
+    Range       *TextRange
+    DeletedText string             // Captured for reversibility
+}
+```
+
+## 3. Serialization
+The DAG is serialized to JSON. This format is human-readable and easy to parse, making it suitable for debugging, storage, and inter-process communication.
+
+### 3.1. Schema
+```json
+{
+  "nodes": {
+    "node_123": {
+      "id": "node_123",
+      "operation": { ... },
+      "parents": ["node_122"]
+    },
+    ...
+  },
+  "roots": ["node_0"],
+  "tips": ["node_123"]
+}
+```
+
+## 4. Semantic Diffing
+Diffing in an Operation DAG is fundamentally different from text diffing. It answers the question: "What operations happened in Branch B that did not happen in Branch A?"
+
+### 4.1. Algorithm
+1.  **Identify Ancestry**: Compute the set of all ancestors for both Key nodes (Base and Target).
+2.  **Set Subtraction**: `Diff = Ancestors(Target) - Ancestors(Base)`.
+3.  **Topological Sort**: Order the resulting set of nodes by dependency to ensure a valid execution order.
+
+### 4.2. Output
+The output of a semantic diff is a "Patch" — a sequence of `ResolvedOperation`s. This patch can be applied to the Base state to reach the Target state (assuming no conflicts).
+
+## 5. Git Integration Strategy
+While the internal IR is a DAG, we can project this onto Git's version control model.
+
+1.  **Commit Mapping**: A Git Commit corresponds to a snapshot of the DAG. The commit message can reference specific DAG Node IDs.
+2.  **Semantic Blame**: Instead of line-based blame, we can trace the DAG backwards to find the node responsible for the current state of a text range.
+3.  **Conflict Resolution**: When Git detects a merge conflict, we can use the DAG structure to identify if the conflict is purely textual or semantically non-colliding (e.g., disjoint edits), potentially resolving it automatically.
+
+## 6. Future Extensions
+*   **Signatures**: Cryptographic signing of DAG nodes for author verification.
+*   **Compression**: Snapshotting state at intervals to avoid traversing the entire history.
+*   **CRDT Integration**: If real-time character-by-character collaboration is needed, nodes can be CRDT operations.
diff --git a/editor/dag.go b/editor/dag.go
new file mode 100644
index 0000000..53ae60b
--- /dev/null
+++ b/editor/dag.go
@@ -0,0 +1,93 @@
+package editor
+
+import (
+	"encoding/json"
+	"fmt"
+	"time"
+)
+
+// DAGNodeID Unique identifier for a node in the DAG
+type DAGNodeID string
+
+// DAGNode represents a single atomic operation in the edit graph
+type DAGNode struct {
+	ID        DAGNodeID         `json:"id"`
+	Operation ResolvedOperation `json:"operation"`
+	Parents   []DAGNodeID       `json:"parents"` // Dependencies
+	Timestamp int64             `json:"timestamp"`
+	Meta      map[string]string `json:"meta,omitempty"`
+}
+
+// OperationDAG represents a Directed Acyclic Graph of operations
+// This is the core IR for collaborative editing and advanced history
+type OperationDAG struct {
+	Nodes map[DAGNodeID]*DAGNode `json:"nodes"`
+	Roots []DAGNodeID            `json:"roots"`
+	Tips  []DAGNodeID            `json:"tips"` // Operations with no children (latest state)
+}
+
+// NewOperationDAG creates a new empty DAG
+func NewOperationDAG() *OperationDAG {
+	return &OperationDAG{
+		Nodes: make(map[DAGNodeID]*DAGNode),
+		Roots: []DAGNodeID{},
+		Tips:  []DAGNodeID{},
+	}
+}
+
+// AddNode adds a new operation to the DAG
+func (dag *OperationDAG) AddNode(op ResolvedOperation, parents []DAGNodeID) (*DAGNode, error) {
+	// Verify parents exist
+	for _, pid := range parents {
+		if _, ok := dag.Nodes[pid]; !ok {
+			return nil, fmt.Errorf("parent node %s not found", pid)
+		}
+	}
+
+	node := &DAGNode{
+		ID:        DAGNodeID(fmt.Sprintf("node_%d_%d", time.Now().UnixNano(), len(dag.Nodes))),
+		Operation: op,
+		Parents:   parents,
+		Timestamp: time.Now().UnixNano(),
+	}
+
+	dag.Nodes[node.ID] = node
+
+	// Update Tips
+	// 1. Remove parents from Tips (they are no longer tips)
+	newTips := []DAGNodeID{}
+	parentSet := make(map[DAGNodeID]bool)
+	for _, pid := range parents {
+		parentSet[pid] = true
+	}
+
+	for _, tip := range dag.Tips {
+		if !parentSet[tip] {
+			newTips = append(newTips, tip)
+		}
+	}
+	// 2. Add new node to Tips
+	newTips = append(newTips, node.ID)
+	dag.Tips = newTips
+
+	// Update Roots if no parents
+	if len(parents) == 0 {
+		dag.Roots = append(dag.Roots, node.ID)
+	}
+
+	return node, nil
+}
+
+// Serialize serializes the DAG to JSON
+func (dag *OperationDAG) Serialize() ([]byte, error) {
+	return json.Marshal(dag)
+}
+
+// DeserializeDAG deserializes a DAG from JSON
+func DeserializeDAG(data []byte) (*OperationDAG, error) {
+	var dag OperationDAG
+	if err := json.Unmarshal(data, &dag); err != nil {
+		return nil, err
+	}
+	return &dag, nil
+}
diff --git a/editor/dag_traversal.go b/editor/dag_traversal.go
new file mode 100644
index 0000000..6b56f9a
--- /dev/null
+++ b/editor/dag_traversal.go
@@ -0,0 +1,173 @@
+package editor
+
+import (
+	"container/list"
+	"fmt"
+)
+
+// GetAncestors returns a set of all ancestor IDs for the given node
+func (dag *OperationDAG) GetAncestors(nodeID DAGNodeID) map[DAGNodeID]bool {
+	ancestors := make(map[DAGNodeID]bool)
+	queue := list.New()
+	queue.PushBack(nodeID)
+
+	visited := make(map[DAGNodeID]bool)
+	visited[nodeID] = true
+
+	for queue.Len() > 0 {
+		element := queue.Front()
+		queue.Remove(element)
+		currentID := element.Value.(DAGNodeID)
+
+		node, exists := dag.Nodes[currentID]
+		if !exists {
+			continue
+		}
+
+		for _, parentID := range node.Parents {
+			if !visited[parentID] {
+				ancestors[parentID] = true
+				visited[parentID] = true
+				queue.PushBack(parentID)
+			}
+		}
+	}
+	return ancestors
+}
+
+// FindLCA finds the Lowest Common Ancestor(s) between two nodes
+// Note: In a DAG, there can be multiple LCAs. This returns one of them, usually the most recent.
+func (dag *OperationDAG) FindLCA(a, b DAGNodeID) DAGNodeID {
+	ancestorsA := dag.GetAncestors(a)
+	ancestorsA[a] = true // Include self
+
+	// BFS from b upwards to find the first node that is in ancestorsA
+	queue := list.New()
+	queue.PushBack(b)
+	visited := make(map[DAGNodeID]bool)
+	visited[b] = true
+
+	if ancestorsA[b] {
+		return b
+	}
+
+	for queue.Len() > 0 {
+		element := queue.Front()
+		queue.Remove(element)
+		currentID := element.Value.(DAGNodeID)
+
+		// If current is in A's ancestry, it's a common ancestor.
+		// Since we traverse BFS (reverse time), the first one we see is an "LCA".
+		// (Approximate definition for "Recent" common ancestor)
+		if ancestorsA[currentID] {
+			return currentID
+		}
+
+		node, exists := dag.Nodes[currentID]
+		if !exists {
+			continue
+		}
+
+		for _, parentID := range node.Parents {
+			if !visited[parentID] {
+				visited[parentID] = true
+				queue.PushBack(parentID)
+			}
+		}
+	}
+
+	return "" // No common ancestor found (disjoint graphs)
+}
+
+// Diff returns the list of operations required to move from 'base' to 'target'.
+// It returns the nodes that are in Target's history but NOT in Base's history.
+// This is effectively "git log base..target".
+// The operations are returned in topological order (dependency order).
+func (dag *OperationDAG) Diff(base, target DAGNodeID) ([]*DAGNode, error) {
+	if _, ok := dag.Nodes[base]; !ok {
+		return nil, fmt.Errorf("base node %s not found", base)
+	}
+	if _, ok := dag.Nodes[target]; !ok {
+		return nil, fmt.Errorf("target node %s not found", target)
+	}
+
+	baseAncestors := dag.GetAncestors(base)
+	baseAncestors[base] = true
+
+	// Collect all nodes in Target's ancestry that are NOT in Base's ancestry
+
+	// We need topological sort.
+	// Simple approach: Collect all candidates, then sort.
+
+	candidates := make(map[DAGNodeID]*DAGNode)
+	queue := list.New()
+	queue.PushBack(target)
+	visited := make(map[DAGNodeID]bool)
+	visited[target] = true
+
+	for queue.Len() > 0 {
+		element := queue.Front()
+		queue.Remove(element)
+		currentID := element.Value.(DAGNodeID)
+
+		if baseAncestors[currentID] {
+			continue // Stop traversing down this branch, it's already known to base
+		}
+
+		node, _ := dag.Nodes[currentID]
+		candidates[currentID] = node
+
+		for _, parentID := range node.Parents {
+			if !visited[parentID] {
+				visited[parentID] = true
+				queue.PushBack(parentID)
+			}
+		}
+	}
+
+	// Now sort candidates topologically
+	// Kahn's algorithm or simpler: just reverse the BFS?
+	// BFS reverse gives roughly topological but not strict.
+	// Since we have the full map, we can just sort by dependency.
+
+	result := make([]*DAGNode, 0, len(candidates))
+
+	// Copy map to work with
+	remaining := make(map[DAGNodeID]bool)
+	for id := range candidates {
+		remaining[id] = true
+	}
+
+	for len(remaining) > 0 {
+		var nextBatch []DAGNodeID
+
+		// Find nodes whose parents are ALL either not in 'remaining' (i.e. processed or base)
+		for id := range remaining {
+			node := candidates[id]
+			ready := true
+			for _, p := range node.Parents {
+				if remaining[p] {
+					ready = false
+					break
+				}
+			}
+			if ready {
+				nextBatch = append(nextBatch, id)
+			}
+		}
+
+		if len(nextBatch) == 0 {
+			// Cycle detected or logic error, break to avoid infinite loop
+			return nil, fmt.Errorf("cycle detected or topo sort error")
+		}
+
+		// Sort batch by timestamp for determinism?
+		// For now just append
+		for _, id := range nextBatch {
+			result = append(result, candidates[id])
+			delete(remaining, id)
+		}
+	}
+
+	return result, nil
+}
diff --git a/weaver/adapter/tmux_projection.go b/weaver/adapter/tmux_projection.go
index f4bbaff..65c173d 100644
--- a/weaver/adapter/tmux_projection.go
+++ b/weaver/adapter/tmux_projection.go
@@ -45,7 +45,12 @@ func (p *TmuxProjection) Apply(resolved []core.ResolvedAnchor, facts []core.Reso
 
 		switch fact.Kind {
 		case core.FactDelete:
-			PerformPhysicalDelete(motion, targetPane)
+			// Phase 5.5: Support Text Object execution
+			if to, ok := fact.Meta["text_object"].(string); ok {
+				PerformPhysicalDelete(to, targetPane)
+			} else {
+				PerformPhysicalDelete(motion, targetPane)
+			}
 
 		case core.FactInsert:
 			// Insert 有两种情况：真正的插入文本，或者进入插入模式动作
diff --git a/weaver/core/shadow_engine.go b/weaver/core/shadow_engine.go
index 9f05f9c..4b4070f 100644
--- a/weaver/core/shadow_engine.go
+++ b/weaver/core/shadow_engine.go
@@ -7,6 +7,7 @@ import (
 	"fmt"
 	"log"
 	"time"
+	"tmux-fsm/editor"
 )
 
 // ShadowEngine 核心执行引擎
@@ -18,6 +19,7 @@ type ShadowEngine struct {
 	projection   Projection
 	reality      RealityReader
 	proofBuilder *ProofBuilder
+	dag          *editor.OperationDAG
 }
 
 func NewShadowEngine(planner Planner, resolver AnchorResolver, projection Projection, reality RealityReader) *ShadowEngine {
@@ -28,6 +30,7 @@ func NewShadowEngine(planner Planner, resolver AnchorResolver, projection Projec
 		projection:   projection,
 		reality:      reality,
 		proofBuilder: NewProofBuilder(),
+		dag:          editor.NewOperationDAG(),
 	}
 }
 
@@ -443,7 +446,53 @@ func (e *ShadowEngine) ApplyIntent(hctx HandleContext, intent Intent, snapshot S
 		log.Printf("Bound ProofHash to transaction %s: %s", txID, tx.ProofHash)
 	}
 
-	log.Printf("Successfully applied intent for pane %s, transaction %s", intent.GetPaneID(), txID)
+	// Phase 6.0: Populate DAG
+	if e.dag != nil && len(resolvedFacts) > 0 {
+		// Use the first fact as the primary operation? or Create a node for each?
+		// Usually atomic intent -> atomic DAG node.
+		// If multiple facts (e.g. multiple cursors), we might need composite node or multiple nodes.
+		// For now, let's assume 1:1 or 1:N mapping where intent is the grouper.
+		// But DAGNode stores 'ResolvedOperation'.
+		// If we store the *Intent* as the semantic parent, we might want one Node per Intent.
+		// However, editor.ResolvedOperation is fine-grained.
+
+		parentIDs := e.dag.Tips // Use current tips as parents
+
+		for _, rf := range resolvedFacts {
+			op := convertFactToOp(rf)
+			_, err := e.dag.AddNode(op, parentIDs)
+			if err != nil {
+				log.Printf("Failed to add node to DAG: %v", err)
+			}
+			// Sequence them? If we add all with same parents, they are concurrent.
+			// Facts in a transaction are atomic/simultaneous.
+			// So using same 'parentIDs' (previous tips) is correct for "parallel" application on state?
+			// Or should they be sequenced?
+			// If facts are ordered (e.g. sequential edits), we should chain them.
+			// Current Planner usually produces independent facts or sequenced?
+			// Assumption: Sequenced.
+			// Let's update parentIDs for next fact to chain them.
+			// But Transaction is Atomic.
+			// Let's chain them for safety.
+			// Actually, reusing same parents means they are parallel forks.
+			// Ideally, we want a single DAG Node representing the Transaction?
+			// But DAGNode holds ResolvedOperation (singular).
+			// Let's chain them.
+			// Note: We need to retrieve the new node's ID to use as parent for next.
+			// But AddNode returns *DAGNode.
+			// Since we just added it, it becomes a Tip.
+			// So for the next iteration, we should use the *new* tips?
+			// e.dag.Tips will be updated by AddNode.
+			// So if we just pass e.dag.Tips, are we implicitly chaining?
+			// e.dag.Tips will contain the *newly added node*.
+			// So yes, chaining happens naturally if we use e.dag.Tips.
+			// But for the *first* fact, we use pre-tx tips.
+			// For *subsequent* facts in same tx, we use the tip created by previous fact.
+			parentIDs = e.dag.Tips
+		}
+	}
+
+	log.Printf("Successfully applied intent for pane %s, transaction %s", intent.GetPaneID(), intent.GetPaneID())
 	return &Verdict{
 		Kind:        VerdictApplied,
 		Message:     "Applied via Smart Projection",
@@ -1043,3 +1092,28 @@ func HashProof(p *Proof) string {
 	sum := sha256.Sum256(b)
 	return hex.EncodeToString(sum[:])
 }
+
+// Convert ResolvedFact to Editor Operation for DAG
+func convertFactToOp(f ResolvedFact) editor.ResolvedOperation {
+	var op editor.ResolvedOperation
+	
+	op.BufferID = editor.BufferID(f.Anchor.PaneID)
+	op.Anchor = editor.Cursor{Row: f.Anchor.Line, Col: f.Anchor.Start}
+	
+	switch f.Kind {
+	case FactInsert:
+		op.Kind = editor.OpInsert
+		op.Text = f.Payload.Text
+	case FactDelete:
+		op.Kind = editor.OpDelete
+		op.Range = &editor.TextRange{
+			Start: editor.Cursor{Row: f.Anchor.Line, Col: f.Anchor.Start},
+			End:   editor.Cursor{Row: f.Anchor.Line, Col: f.Anchor.End},
+		}
+		op.DeletedText = f.Payload.OldText
+	case FactMove:
+		op.Kind = editor.OpMove
+	}
+	
+	return op
+}
diff --git a/weaver/core/types.go b/weaver/core/types.go
index 39d1571..f3c35ba 100644
--- a/weaver/core/types.go
+++ b/weaver/core/types.go
@@ -14,6 +14,7 @@ const (
 	AnchorLine
 	AnchorAbsolute
 	AnchorLegacyRange
+	AnchorTextObject
 )
 
 // SafetyLevel 安全级别
diff --git a/weaver/logic/passthrough_resolver.go b/weaver/logic/passthrough_resolver.go
index 3e85292..62c3186 100644
--- a/weaver/logic/passthrough_resolver.go
+++ b/weaver/logic/passthrough_resolver.go
@@ -128,6 +128,46 @@ func (r *PassthroughResolver) resolveAnchorWithSnapshot(a core.Anchor, s core.Sn
 		return core.ResolvedAnchor{PaneID: a.PaneID, LineID: lineID, Line: row, Start: start, End: end}, nil
 	case core.AnchorLine:
 		return core.ResolvedAnchor{PaneID: a.PaneID, LineID: lineID, Line: row, Start: 0, End: len(lineText) - 1}, nil
+	case core.AnchorTextObject:
+		specStr, ok := a.Ref.(string)
+		if !ok {
+			return core.ResolvedAnchor{}, fmt.Errorf("invalid text object ref")
+		}
+		spec := ParseTextObject(specStr)
+
+		doc := Document{Snapshot: s}
+		loc := Loc{Line: row, Col: col}
+		rng := ResolveTextObject(doc, loc, spec)
+
+		// Map LocRange back to ResolvedAnchor (assuming single line for now? No, resolved object can be multi-line!)
+		// But ResolvedAnchor structure assumes single LineID?
+		// Check core/types.go: ResolvedAnchor has LineID, Line, Start, End.
+		// It seems designed for single-line anchors.
+		// If TextObject is multi-line (paragraph), we might have issues.
+		// Phase 6.0 DAG defines Operation as single node? Or list of nodes?
+		// Let's assume for now we resolve to the start/end linear range if possible, or force single line
+		// if ResolvedAnchor doesn't support multiline.
+		// Wait, ResolvedAnchor has NO end line. It implies single line?
+		// Let's check core/types.go specifically for `ResolvedAnchor` definition.
+		// Wait, I can't check it now easily without reading again.
+		// Assuming ResolvedAnchor IS single line based on previous usage (Line, Start, End).
+		// If so, we need to handle multi-line text objects by potentially returning multiple ResolvedAnchors?
+		// But ResolveFacts returns []ResolvedFact, one per Fact. One Fact has one Anchor.
+		// So one Fact = One Continuous Range?
+		// If TextObject is multi-line, maybe we need to split it into multiple Facts/Anchors?
+		// Or update ResolvedAnchor to support multi-line.
+		// For `diw`, it is single line. Let's support `diw` first.
+
+		if rng.Start.Line != rng.End.Line {
+			// Multi-line object
+			// Fallback: just return start? Or error?
+			// For Phase 5.5, let's limit to single line or simple ranges.
+			return core.ResolvedAnchor{PaneID: a.PaneID, LineID: lineID, Line: rng.Start.Line, Start: rng.Start.Col, End: rng.End.Col}, nil
+		}
+
+		// Identical line
+		return core.ResolvedAnchor{PaneID: a.PaneID, LineID: lineID, Line: rng.Start.Line, Start: rng.Start.Col, End: rng.End.Col}, nil
+
 	case core.AnchorAbsolute:
 		// Ref is expected to be []int{line, col}
 		if coords, ok := a.Ref.([]int); ok && len(coords) >= 2 {
@@ -178,6 +218,14 @@ func (r *PassthroughResolver) resolveAnchor(a core.Anchor) (core.ResolvedAnchor,
 			End:    col,
 		}, nil
 
+	case core.AnchorTextObject:
+		// Without snapshot, we need to read the document?
+		// PassthroughResolver has RealityReader.
+		// But Document expects Snapshot.
+		// We can try to build a transient snapshot?
+		// Or just fail if no snapshot?
+		return core.ResolvedAnchor{}, fmt.Errorf("text object resolution requires snapshot")
+
 	case core.AnchorWord:
 		// use lineText already captured
 		start, end := findWordRange(lineText, col, false)
diff --git a/weaver/logic/shell_fact_builder.go b/weaver/logic/shell_fact_builder.go
index 8da92ff..2ab42ff 100644
--- a/weaver/logic/shell_fact_builder.go
+++ b/weaver/logic/shell_fact_builder.go
@@ -46,8 +46,11 @@ func (b *ShellFactBuilder) Build(intent core.Intent, snapshot core.Snapshot) ([]
 			anchor.Kind = core.AnchorWord
 		case 3: // Line
 			anchor.Kind = core.AnchorLine
-		case 5: // TextObject
-			anchor.Kind = core.AnchorWord // Fallback or sophisticated resolution
+		case 6: // TextObject
+			anchor.Kind = core.AnchorTextObject
+			// We need to attach the text object spec to the anchor.
+			// Anchor has 'Ref'. usage: Ref = "iw"
+			anchor.Ref = target.Value
 		}
 
 		anchors = []core.Anchor{anchor}
@@ -66,9 +69,23 @@ func (b *ShellFactBuilder) Build(intent core.Intent, snapshot core.Snapshot) ([]
 				Meta:    meta,
 			})
 
-		// Note: IntentDelete and IntentChange intentionally omitted for Shell.
-		// We rely on high-fidelity legacy capture and reverse-bridge injection
-		// because semantic word-boundary resolution in the shell is imprecise.
+		case core.IntentDelete:
+			// Phase 5.5: Support Text Object Delete in shell builder
+			// If target is Text Object, we must generate a FactDelete with AnchorTextObject
+			if target.Kind == 6 { // TextObject (TargetTextObject=6)
+				// Extract "iw", "ap" etc from value
+				// The semantic target value for TextObject is the spec string (e.g. "iw")
+				meta["text_object"] = target.Value
+
+				facts = append(facts, core.Fact{
+					Kind:   core.FactDelete,
+					Anchor: anchor, // This anchor needs to be Kind=AnchorTextObject
+					Meta:   meta,
+				})
+			} else {
+				// Fallback or other delete types?
+				// For now, only enabling TextObject delete in this path as requested.
+			}
 
 		case core.IntentMove:
 			// Move is FactMove.
diff --git a/weaver/logic/text_object.go b/weaver/logic/text_object.go
new file mode 100644
index 0000000..925a20d
--- /dev/null
+++ b/weaver/logic/text_object.go
@@ -0,0 +1,434 @@
+package logic
+
+import (
+	"tmux-fsm/weaver/core"
+	"unicode"
+)
+
+// TextObjectKind defines the kind of text object
+// Duplicates main package for Weaver isolation
+type TextObjectKind int
+
+const (
+	ObjectWord TextObjectKind = iota
+	ObjectWORD
+	ObjectSentence
+	ObjectParagraph
+	ObjectDelimited
+)
+
+// TextObjectSpec represents a parsed text object intent
+type TextObjectSpec struct {
+	Kind   TextObjectKind
+	Inner  bool
+	DelimL rune
+	DelimR rune
+}
+
+// Document wraps Snapshot to provide navigation methods for Text Object Resolver
+type Document struct {
+	Snapshot core.Snapshot
+}
+
+// Loc represents a location in terms of line index and rune index (column)
+type Loc struct {
+	Line int
+	Col  int
+}
+
+// ParseTextObject parses "iw", "ap", "a{" into a spec
+func ParseTextObject(input string) TextObjectSpec {
+	if len(input) != 2 {
+		panic("invalid text object input length")
+	}
+
+	if input[0] != 'i' && input[0] != 'a' {
+		panic("invalid text object modifier: " + string(input[0]))
+	}
+
+	spec := TextObjectSpec{}
+	spec.Inner = (input[0] == 'i')
+
+	switch input[1] {
+	case 'w':
+		spec.Kind = ObjectWord
+	case 'W':
+		spec.Kind = ObjectWORD
+	case 's':
+		spec.Kind = ObjectSentence
+	case 'p':
+		spec.Kind = ObjectParagraph
+
+	case '(', ')':
+		spec.Kind = ObjectDelimited
+		spec.DelimL = '('
+		spec.DelimR = ')'
+
+	case '{', '}':
+		spec.Kind = ObjectDelimited
+		spec.DelimL = '{'
+		spec.DelimR = '}'
+
+	case '[', ']':
+		spec.Kind = ObjectDelimited
+		spec.DelimL = '['
+		spec.DelimR = ']'
+
+	case '"', '\'', '`':
+		r := rune(input[1])
+		spec.Kind = ObjectDelimited
+		spec.DelimL = r
+		spec.DelimR = r
+
+	case '<', '>':
+		spec.Kind = ObjectDelimited
+		spec.DelimL = '<'
+		spec.DelimR = '>'
+
+	default:
+		panic("unsupported text object: " + string(input[1]))
+	}
+
+	return spec
+}
+
+// Document Methods adapting core.Snapshot
+
+func (d Document) LineCount() int {
+	return len(d.Snapshot.Lines)
+}
+
+func (d Document) RunesAtLine(lineIdx int) []rune {
+	if lineIdx < 0 || lineIdx >= d.LineCount() {
+		return nil
+	}
+	// core.LineSnapshot.Text
+	return []rune(d.Snapshot.Lines[lineIdx].Text)
+}
+
+func (d Document) RuneAt(l Loc) rune {
+	runes := d.RunesAtLine(l.Line)
+	if runes == nil {
+		return 0
+	}
+	if l.Col < 0 || l.Col >= len(runes) {
+		return 0
+	}
+	return runes[l.Col]
+}
+
+func (d Document) RuneBefore(l Loc) rune {
+	prev := d.MoveLeft(l)
+	if prev == l {
+		return 0
+	}
+	return d.RuneAt(prev)
+}
+
+func (d Document) IsBOF(l Loc) bool {
+	return l.Line == 0 && l.Col == 0
+}
+
+func (d Document) IsEOF(l Loc) bool {
+	lastLineIdx := d.LineCount() - 1
+	if lastLineIdx < 0 {
+		return true
+	}
+	runes := d.RunesAtLine(lastLineIdx)
+	return l.Line == lastLineIdx && l.Col >= len(runes)
+}
+
+func (d Document) MoveLeft(l Loc) Loc {
+	if l.Col > 0 {
+		return Loc{Line: l.Line, Col: l.Col - 1}
+	}
+	if l.Line > 0 {
+		prevLineIdx := l.Line - 1
+		runes := d.RunesAtLine(prevLineIdx)
+		return Loc{Line: prevLineIdx, Col: len(runes)} // End of prev line (after last char)
+	}
+	return l // BOF
+}
+
+func (d Document) MoveRight(l Loc) Loc {
+	runes := d.RunesAtLine(l.Line)
+	if runes == nil {
+		return l
+	}
+
+	if l.Col < len(runes) {
+		return Loc{Line: l.Line, Col: l.Col + 1}
+	}
+
+	if l.Line < d.LineCount()-1 {
+		return Loc{Line: l.Line + 1, Col: 0}
+	}
+
+	return l // EOF
+}
+
+func (d Document) LineIsWhitespace(lineIdx int) bool {
+	runes := d.RunesAtLine(lineIdx)
+	for _, r := range runes {
+		if !unicode.IsSpace(r) {
+			return false
+		}
+	}
+	return true
+}
+
+// Helpers
+
+func isWhitespace(r rune) bool {
+	return unicode.IsSpace(r)
+}
+
+func isAlphaNum(r rune) bool {
+	return unicode.IsLetter(r) || unicode.IsNumber(r)
+}
+
+// Range logic (Loc based)
+type LocRange struct {
+	Start Loc
+	End   Loc
+}
+
+// Resolvers
+
+func ResolveTextObject(doc Document, cursor Loc, spec TextObjectSpec) LocRange {
+	switch spec.Kind {
+	case ObjectWord:
+		return resolveWord(doc, cursor, spec.Inner, false)
+	case ObjectWORD:
+		return resolveWord(doc, cursor, spec.Inner, true)
+	case ObjectSentence:
+		return resolveSentence(doc, cursor, spec.Inner)
+	case ObjectParagraph:
+		return resolveParagraph(doc, cursor, spec.Inner)
+	case ObjectDelimited:
+		return resolveDelimited(doc, cursor, spec)
+	default:
+		// Should not happen if validation passed
+		return LocRange{Start: cursor, End: cursor}
+	}
+}
+
+func resolveWord(doc Document, cursor Loc, inner bool, big bool) LocRange {
+	isWord := func(r rune) bool {
+		if big {
+			return !isWhitespace(r)
+		}
+		return isAlphaNum(r) || r == '_'
+	}
+
+	pos := cursor
+	if !isWord(doc.RuneAt(pos)) {
+		if inner {
+			// As per panic instruction in previous file, we replicate behavior where appropriate.
+			// However in Weaver we prefer error returns, but this structure panics.
+			// Let's implement robust behavior: if whitespace, treat whitespace as word.
+		}
+
+		if !big {
+			isWord = func(r rune) bool {
+				return isWhitespace(r)
+			}
+		} else {
+			isWord = func(r rune) bool {
+				return isWhitespace(r)
+			}
+		}
+	}
+
+	left := pos
+	for isWord(doc.RuneBefore(left)) {
+		left = doc.MoveLeft(left)
+	}
+
+	right := pos
+	for isWord(doc.RuneAt(right)) {
+		right = doc.MoveRight(right)
+	}
+
+	if inner {
+		return LocRange{Start: left, End: right}
+	}
+
+	// around
+	l := left
+	for isWhitespace(doc.RuneBefore(l)) {
+		l = doc.MoveLeft(l)
+	}
+
+	r := right
+	for isWhitespace(doc.RuneAt(r)) {
+		r = doc.MoveRight(r)
+	}
+
+	return LocRange{Start: l, End: r}
+}
+
+func resolveSentence(doc Document, cursor Loc, inner bool) LocRange {
+	isEnd := func(r rune) bool {
+		return r == '.' || r == '!' || r == '?'
+	}
+
+	left := cursor
+	for !isEnd(doc.RuneBefore(left)) && !doc.IsBOF(left) {
+		left = doc.MoveLeft(left)
+	}
+
+	right := cursor
+	for !isEnd(doc.RuneAt(right)) && !doc.IsEOF(right) {
+		right = doc.MoveRight(right)
+	}
+	right = doc.MoveRight(right)
+
+	r := LocRange{Start: left, End: right}
+
+	if inner {
+		return trimWhitespace(doc, r)
+	}
+	return expandWhitespace(doc, r)
+}
+
+func resolveParagraph(doc Document, cursor Loc, inner bool) LocRange {
+	isBlank := func(lineIdx int) bool {
+		return doc.LineIsWhitespace(lineIdx)
+	}
+
+	l := cursor.Line
+	for l > 0 && !isBlank(l-1) {
+		l--
+	}
+
+	r := cursor.Line
+	for r < doc.LineCount()-1 && !isBlank(r+1) {
+		r++
+	}
+
+	start := Loc{Line: l, Col: 0}
+
+	endLine := r + 1
+	if endLine > doc.LineCount() {
+		endLine = doc.LineCount()
+	}
+	end := Loc{Line: endLine, Col: 0}
+
+	if inner {
+		return LocRange{Start: start, End: end}
+	}
+
+	for l > 0 && isBlank(l-1) {
+		l--
+	}
+
+	rScan := r + 1
+	for rScan < doc.LineCount() && isBlank(rScan) {
+		rScan++
+	}
+
+	return LocRange{
+		Start: Loc{Line: l, Col: 0},
+		End:   Loc{Line: rScan, Col: 0},
+	}
+}
+
+func resolveDelimited(doc Document, cursor Loc, spec TextObjectSpec) LocRange {
+	depth := 0
+	left := doc.MoveLeft(cursor)
+
+	// Find opening
+	for !doc.IsBOF(left) {
+		r := doc.RuneAt(left)
+
+		if r == spec.DelimR {
+			depth++
+		} else if r == spec.DelimL {
+			if depth == 0 {
+				break
+			}
+			depth--
+		}
+		left = doc.MoveLeft(left)
+	}
+
+	// If fail, we technically should error.
+	// For robust logic, return cursor range? Or assume found?
+	// The original had panic.
+	if doc.RuneAt(left) != spec.DelimL {
+		// handle mismatch
+	}
+
+	// Find closing
+	depth = 0
+	right := doc.MoveRight(cursor)
+
+	for !doc.IsEOF(right) {
+		r := doc.RuneAt(right)
+
+		if r == spec.DelimL {
+			depth++
+		} else if r == spec.DelimR {
+			if depth == 0 {
+				break
+			}
+			depth--
+		}
+		right = doc.MoveRight(right)
+	}
+
+	if spec.Inner {
+		return LocRange{
+			Start: doc.MoveRight(left),
+			End:   right, // exclusive of right delim?
+		}
+	}
+
+	return LocRange{
+		Start: left,
+		End:   doc.MoveRight(right),
+	}
+}
+
+func trimWhitespace(doc Document, r LocRange) LocRange {
+	for isWhitespace(doc.RuneAt(r.Start)) {
+		newStart := doc.MoveRight(r.Start)
+		if newStart == r.Start {
+			break
+		}
+		r.Start = newStart
+		if r.Start.Line > r.End.Line || (r.Start.Line == r.End.Line && r.Start.Col >= r.End.Col) {
+			break
+		}
+	}
+	for isWhitespace(doc.RuneBefore(r.End)) {
+		newEnd := doc.MoveLeft(r.End)
+		if newEnd == r.End {
+			break
+		}
+		r.End = newEnd
+		if r.Start.Line > r.End.Line || (r.Start.Line == r.End.Line && r.Start.Col >= r.End.Col) {
+			break
+		}
+	}
+	return r
+}
+
+func expandWhitespace(doc Document, r LocRange) LocRange {
+	for isWhitespace(doc.RuneBefore(r.Start)) {
+		newStart := doc.MoveLeft(r.Start)
+		if newStart == r.Start {
+			break
+		}
+		r.Start = newStart
+	}
+	for isWhitespace(doc.RuneAt(r.End)) {
+		newEnd := doc.MoveRight(r.End)
+		if newEnd == r.End {
+			break
+		}
+		r.End = newEnd
+	}
+	return r
+}
